{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM to Seq2Seq\n",
    "- I will try to use medical examples and apply lstm or seq2seq\n",
    "\n",
    "# LSTM\n",
    "- lstm cell\n",
    "\n",
    "![lstm](https://miro.medium.com/max/900/1*s7_EO0rjXAw99RnH1x4s_g.png)\n",
    "- lstm cell takes 3 input\n",
    "    - cell state from $t-1$\n",
    "    - hidden state from $t-1$\n",
    "    - current input $x_t$\n",
    "\n",
    "- lstm cell output \n",
    "    - cell state from $t$\n",
    "    - hidden state from $t$\n",
    "    - output from $t$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use sample data\n",
    "\n",
    "input : length 1 with 10 dimension\\\n",
    "output : length 1 20 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(10, 20, 1) # (input_size, hidden_size, num_layers)\n",
    "input = torch.randn(1, 1, 10) # (Series Length, Batch size, input_dim)\n",
    "h0 = torch.randn(1, 1, 20) # (Series Length, Batch size, input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 20, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.input_size, rnn.hidden_size, rnn.num_layers\n",
    "# input size , hidden size,  number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = rnn(input)\n",
    "\n",
    "len(output) # length of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0863,  0.0783, -0.0632, -0.2114, -0.0293, -0.1373,  0.0518,\n",
       "            0.0394,  0.1196, -0.1581, -0.0976, -0.0430,  0.0953,  0.1388,\n",
       "           -0.0117, -0.0956,  0.0860, -0.0165, -0.0935, -0.1458]]],\n",
       "        grad_fn=<StackBackward0>),\n",
       " (tensor([[[ 0.0863,  0.0783, -0.0632, -0.2114, -0.0293, -0.1373,  0.0518,\n",
       "             0.0394,  0.1196, -0.1581, -0.0976, -0.0430,  0.0953,  0.1388,\n",
       "            -0.0117, -0.0956,  0.0860, -0.0165, -0.0935, -0.1458]]],\n",
       "         grad_fn=<StackBackward0>),\n",
       "  tensor([[[ 0.1549,  0.1691, -0.2255, -0.3411, -0.1421, -0.2021,  0.0807,\n",
       "             0.0683,  0.1738, -0.3337, -0.1766, -0.1121,  0.2311,  0.2966,\n",
       "            -0.0269, -0.2441,  0.2428, -0.0286, -0.1672, -0.2226]]],\n",
       "         grad_fn=<StackBackward0>)))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0], output[1]\n",
    "\n",
    "# output 0 : 1,1,20 vector. output of layer\n",
    "# output 1 : (output and the hidden output & current state output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we changed the sequence of the vector to 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.rand(2, 1, 10) # sequence length 2, batch_size, 1, embedding size 10\n",
    "rnn = nn.LSTM(10, 20, 1) # same model as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0048,  0.0252, -0.0662,  0.0445, -0.0235,  0.0417,  0.0912,\n",
       "           -0.1003,  0.1035,  0.0425,  0.0040,  0.0461, -0.1268, -0.1497,\n",
       "            0.0053,  0.0726, -0.0384,  0.0635,  0.0502, -0.0389]],\n",
       " \n",
       "         [[-0.0363,  0.0357, -0.0924,  0.0851,  0.0062,  0.0713,  0.0575,\n",
       "           -0.1367,  0.0891,  0.0867,  0.0131,  0.0277, -0.1554, -0.1826,\n",
       "           -0.0610,  0.0499, -0.0329,  0.1127,  0.0623, -0.0623]]],\n",
       "        grad_fn=<StackBackward0>),\n",
       " (tensor([[[-0.0363,  0.0357, -0.0924,  0.0851,  0.0062,  0.0713,  0.0575,\n",
       "            -0.1367,  0.0891,  0.0867,  0.0131,  0.0277, -0.1554, -0.1826,\n",
       "            -0.0610,  0.0499, -0.0329,  0.1127,  0.0623, -0.0623]]],\n",
       "         grad_fn=<StackBackward0>),\n",
       "  tensor([[[-0.0592,  0.0775, -0.1861,  0.1817,  0.0103,  0.1715,  0.1263,\n",
       "            -0.3140,  0.1404,  0.1599,  0.0260,  0.0503, -0.3637, -0.3371,\n",
       "            -0.1354,  0.0950, -0.0755,  0.2138,  0.1307, -0.1480]]],\n",
       "         grad_fn=<StackBackward0>)))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = rnn(input) \n",
    "\n",
    "output[0], output[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 20])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].shape \n",
    "# The hidden state output. \n",
    "\n",
    "# (Length 2, batch, embed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0363,  0.0357, -0.0924,  0.0851,  0.0062,  0.0713,  0.0575,\n",
       "           -0.1367,  0.0891,  0.0867,  0.0131,  0.0277, -0.1554, -0.1826,\n",
       "           -0.0610,  0.0499, -0.0329,  0.1127,  0.0623, -0.0623]]],\n",
       "        grad_fn=<StackBackward0>),\n",
       " tensor([[[-0.0592,  0.0775, -0.1861,  0.1817,  0.0103,  0.1715,  0.1263,\n",
       "           -0.3140,  0.1404,  0.1599,  0.0260,  0.0503, -0.3637, -0.3371,\n",
       "           -0.1354,  0.0950, -0.0755,  0.2138,  0.1307, -0.1480]]],\n",
       "        grad_fn=<StackBackward0>))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[1]\n",
    "\n",
    "# (hidden state : (sequence_size, batch_size, embedding), current_state : (sequence_size, batch_size, embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-LSTM models with some dataset\n",
    "- dataset : Tabular data - titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "project_dir = Path.cwd().parent\n",
    "data_dir = project_dir.joinpath('data')\n",
    "\n",
    "data = data_dir.joinpath('train.csv')\n",
    "data = pd.read_csv(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first tokenize all the values in the dataset\n",
    "data.values\n",
    "\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "vocab = build_vocab_from_iterator(data.values.astype('str'), specials = [\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.transforms import VocabTransform\n",
    "\n",
    "vocab_transform = VocabTransform(vocab)\n",
    "\n",
    "vocab_transform(data.values[0].astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path().exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/_jit_internal.py:1133: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if obj == [] or obj == {} or obj == ():\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/wonseok/2022_transformer/notebook/20220520_lstm-seq2seq.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B61.252.54.67/home/wonseok/2022_transformer/notebook/20220520_lstm-seq2seq.ipynb#ch0000023vscode-remote?line=0'>1</a>\u001b[0m vocab_transform(data\u001b[39m.\u001b[39;49mvalues[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mastype(\u001b[39m'\u001b[39;49m\u001b[39mstr\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mreshape(\u001b[39m1\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torchtext/transforms.py:93\u001b[0m, in \u001b[0;36mVocabTransform.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torchtext/transforms.py?line=84'>85</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m     <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torchtext/transforms.py?line=85'>86</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torchtext/transforms.py?line=86'>87</a>\u001b[0m \u001b[39m    :param input: Input batch of token to convert to correspnding token ids\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torchtext/transforms.py?line=87'>88</a>\u001b[0m \u001b[39m    :type input: Union[List[str], List[List[str]]]\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torchtext/transforms.py?line=88'>89</a>\u001b[0m \u001b[39m    :return: Converted input into corresponding token ids\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torchtext/transforms.py?line=89'>90</a>\u001b[0m \u001b[39m    :rtype: Union[List[int], List[List[int]]]\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torchtext/transforms.py?line=90'>91</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torchtext/transforms.py?line=92'>93</a>\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49misinstance(\u001b[39minput\u001b[39;49m, List[\u001b[39mstr\u001b[39;49m]):\n\u001b[1;32m     <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torchtext/transforms.py?line=93'>94</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab\u001b[39m.\u001b[39mlookup_indices(\u001b[39minput\u001b[39m)\n\u001b[1;32m     <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torchtext/transforms.py?line=94'>95</a>\u001b[0m     \u001b[39melif\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39misinstance(\u001b[39minput\u001b[39m, List[List[\u001b[39mstr\u001b[39m]]):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/jit/__init__.py:187\u001b[0m, in \u001b[0;36misinstance\u001b[0;34m(obj, target_type)\u001b[0m\n\u001b[1;32m    <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/jit/__init__.py?line=147'>148</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, target_type):\n\u001b[1;32m    <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/jit/__init__.py?line=148'>149</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/jit/__init__.py?line=149'>150</a>\u001b[0m \u001b[39m    This function provides for conatiner type refinement in TorchScript. It can refine\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/jit/__init__.py?line=150'>151</a>\u001b[0m \u001b[39m    parameterized containers of the List, Dict, Tuple, and Optional types. E.g. ``List[str]``,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/jit/__init__.py?line=184'>185</a>\u001b[0m \u001b[39m        m(y)\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/jit/__init__.py?line=185'>186</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/jit/__init__.py?line=186'>187</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _isinstance(obj, target_type)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/_jit_internal.py:1218\u001b[0m, in \u001b[0;36m_isinstance\u001b[0;34m(obj, target_type)\u001b[0m\n\u001b[1;32m   <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/_jit_internal.py?line=1215'>1216</a>\u001b[0m origin_type \u001b[39m=\u001b[39m get_origin(target_type)\n\u001b[1;32m   <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/_jit_internal.py?line=1216'>1217</a>\u001b[0m \u001b[39mif\u001b[39;00m origin_type:\n\u001b[0;32m-> <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/_jit_internal.py?line=1217'>1218</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m container_checker(obj, target_type)\n\u001b[1;32m   <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/_jit_internal.py?line=1219'>1220</a>\u001b[0m \u001b[39m# Check to handle weird python type behaviors\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/_jit_internal.py?line=1220'>1221</a>\u001b[0m \u001b[39m# 1. python 3.6 returns None for origin of containers without\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/_jit_internal.py?line=1221'>1222</a>\u001b[0m \u001b[39m#    contained type (intead of returning outer container type)\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/_jit_internal.py?line=1222'>1223</a>\u001b[0m \u001b[39m# 2. non-typed optional origin returns as none instead\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/_jit_internal.py?line=1223'>1224</a>\u001b[0m \u001b[39m#    of as optional in 3.6-3.8\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/_jit_internal.py?line=1224'>1225</a>\u001b[0m check_args_exist(target_type)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/_jit_internal.py:1147\u001b[0m, in \u001b[0;36mcontainer_checker\u001b[0;34m(obj, target_type)\u001b[0m\n\u001b[1;32m   <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/_jit_internal.py?line=1144'>1145</a>\u001b[0m check_args_exist(target_type)\n\u001b[1;32m   <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/_jit_internal.py?line=1145'>1146</a>\u001b[0m \u001b[39mif\u001b[39;00m origin_type \u001b[39mis\u001b[39;00m \u001b[39mlist\u001b[39m \u001b[39mor\u001b[39;00m origin_type \u001b[39mis\u001b[39;00m List:\n\u001b[0;32m-> <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/_jit_internal.py?line=1146'>1147</a>\u001b[0m     check_empty_containers(obj)\n\u001b[1;32m   <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/_jit_internal.py?line=1147'>1148</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, \u001b[39mlist\u001b[39m):\n\u001b[1;32m   <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/_jit_internal.py?line=1148'>1149</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/_jit_internal.py:1133\u001b[0m, in \u001b[0;36mcheck_empty_containers\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/_jit_internal.py?line=1131'>1132</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_empty_containers\u001b[39m(obj) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/_jit_internal.py?line=1132'>1133</a>\u001b[0m     \u001b[39mif\u001b[39;00m obj \u001b[39m==\u001b[39m [] \u001b[39mor\u001b[39;00m obj \u001b[39m==\u001b[39m {} \u001b[39mor\u001b[39;00m obj \u001b[39m==\u001b[39m ():\n\u001b[1;32m   <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/_jit_internal.py?line=1133'>1134</a>\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe inner type of a container is lost when \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/_jit_internal.py?line=1134'>1135</a>\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mcalling torch.jit.isinstance in eager mode. For \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/_jit_internal.py?line=1135'>1136</a>\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mexample, List[int] would become list and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/_jit_internal.py?line=1136'>1137</a>\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mtherefore falsely return True for List[float] or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///home/wonseok/.pyenv/versions/3.8.12/envs/2022_transformer/lib/python3.8/site-packages/torch/_jit_internal.py?line=1137'>1138</a>\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39m List[str].\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "vocab_transform(data.values[0].astype('str').reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to Sequence\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2a8cca9f7ae2054f045beba9ed73ad6f832c9901de5708c28ae510697f529c7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('2022_transformer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
