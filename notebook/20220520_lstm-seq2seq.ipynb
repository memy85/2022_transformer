{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM to Seq2Seq\n",
    "- I will try to use medical examples and apply lstm or seq2seq\n",
    "\n",
    "# LSTM\n",
    "- lstm cell\n",
    "\n",
    "![lstm](https://miro.medium.com/max/900/1*s7_EO0rjXAw99RnH1x4s_g.png)\n",
    "- lstm cell takes 3 input\n",
    "    - cell state from $t-1$\n",
    "    - hidden state from $t-1$\n",
    "    - current input $x_t$\n",
    "\n",
    "- lstm cell output \n",
    "    - cell state from $t$\n",
    "    - hidden state from $t$\n",
    "    - output from $t$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use sample data\n",
    "\n",
    "input : length 1 with 10 dimension\\\n",
    "output : length 1 20 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(10, 20, 1) # (input_size, hidden_size, num_layers)\n",
    "input = torch.randn(1, 1, 10) # (Series Length, Batch size, input_dim)\n",
    "h0 = torch.randn(1, 1, 20) # (Series Length, Batch size, input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 20, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.input_size, rnn.hidden_size, rnn.num_layers\n",
    "# input size , hidden size,  number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = rnn(input)\n",
    "\n",
    "len(output) # length of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0132, -0.0280, -0.0658, -0.1545, -0.0591, -0.0473, -0.0345,\n",
       "           -0.0801, -0.0236, -0.0128,  0.0644,  0.0250,  0.0543, -0.0052,\n",
       "            0.0689,  0.1972,  0.0581, -0.0217,  0.0296,  0.0013]]],\n",
       "        grad_fn=<StackBackward0>),\n",
       " (tensor([[[-0.0132, -0.0280, -0.0658, -0.1545, -0.0591, -0.0473, -0.0345,\n",
       "            -0.0801, -0.0236, -0.0128,  0.0644,  0.0250,  0.0543, -0.0052,\n",
       "             0.0689,  0.1972,  0.0581, -0.0217,  0.0296,  0.0013]]],\n",
       "         grad_fn=<StackBackward0>),\n",
       "  tensor([[[-0.0518, -0.0666, -0.1378, -0.2368, -0.0937, -0.0823, -0.0700,\n",
       "            -0.1625, -0.0501, -0.0252,  0.1349,  0.0626,  0.1445, -0.0095,\n",
       "             0.1098,  0.3380,  0.1332, -0.0594,  0.0631,  0.0026]]],\n",
       "         grad_fn=<StackBackward0>)))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hid[0], hid[1]\n",
    "\n",
    "# hid 0 : 1,1,20 vector. output of layer\n",
    "# hid 1 : output and the hidden output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we changed the sequence of the vector to 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.rand(2, 1, 10) # sequence length 2, batch_size, 1, embedding size 10\n",
    "rnn = nn.LSTM(10, 20, 1) # same model as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0309, -0.0423,  0.1113,  0.0156, -0.0065, -0.0085, -0.0040,\n",
       "           -0.0005,  0.0153, -0.0890,  0.0052, -0.0507, -0.0158, -0.1325,\n",
       "           -0.1681, -0.0311, -0.0812, -0.0822,  0.0467, -0.0707],\n",
       "          [-0.0585,  0.0160,  0.0479,  0.0101, -0.0034,  0.0336,  0.0124,\n",
       "           -0.0171, -0.0414, -0.0824,  0.0455, -0.0525, -0.0245, -0.0968,\n",
       "           -0.1602, -0.0516, -0.1210, -0.0785,  0.0693, -0.0572]]],\n",
       "        grad_fn=<StackBackward0>),\n",
       " (tensor([[[-0.0309, -0.0423,  0.1113,  0.0156, -0.0065, -0.0085, -0.0040,\n",
       "            -0.0005,  0.0153, -0.0890,  0.0052, -0.0507, -0.0158, -0.1325,\n",
       "            -0.1681, -0.0311, -0.0812, -0.0822,  0.0467, -0.0707],\n",
       "           [-0.0585,  0.0160,  0.0479,  0.0101, -0.0034,  0.0336,  0.0124,\n",
       "            -0.0171, -0.0414, -0.0824,  0.0455, -0.0525, -0.0245, -0.0968,\n",
       "            -0.1602, -0.0516, -0.1210, -0.0785,  0.0693, -0.0572]]],\n",
       "         grad_fn=<StackBackward0>),\n",
       "  tensor([[[-0.0722, -0.0787,  0.2079,  0.0371, -0.0137, -0.0175, -0.0101,\n",
       "            -0.0013,  0.0336, -0.1590,  0.0095, -0.1277, -0.0280, -0.2336,\n",
       "            -0.3148, -0.0516, -0.1679, -0.1845,  0.0883, -0.1662],\n",
       "           [-0.1315,  0.0312,  0.1007,  0.0234, -0.0065,  0.0748,  0.0284,\n",
       "            -0.0347, -0.0846, -0.1573,  0.0839, -0.1238, -0.0416, -0.1630,\n",
       "            -0.3132, -0.0836, -0.2504, -0.1760,  0.1154, -0.1191]]],\n",
       "         grad_fn=<StackBackward0>)))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = rnn(input)\n",
    "\n",
    "output[0], output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 20])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].shape \n",
    "# The hidden state output. \n",
    "# (Length 2, batch, embed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0309, -0.0423,  0.1113,  0.0156, -0.0065, -0.0085, -0.0040,\n",
       "          -0.0005,  0.0153, -0.0890,  0.0052, -0.0507, -0.0158, -0.1325,\n",
       "          -0.1681, -0.0311, -0.0812, -0.0822,  0.0467, -0.0707],\n",
       "         [-0.0585,  0.0160,  0.0479,  0.0101, -0.0034,  0.0336,  0.0124,\n",
       "          -0.0171, -0.0414, -0.0824,  0.0455, -0.0525, -0.0245, -0.0968,\n",
       "          -0.1602, -0.0516, -0.1210, -0.0785,  0.0693, -0.0572]]],\n",
       "       grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2a8cca9f7ae2054f045beba9ed73ad6f832c9901de5708c28ae510697f529c7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('2022_transformer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
