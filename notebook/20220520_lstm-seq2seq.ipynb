{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM to Seq2Seq\n",
    "- I will try to use medical examples and apply lstm or seq2seq\n",
    "\n",
    "# LSTM\n",
    "- lstm cell\n",
    "\n",
    "![lstm](https://miro.medium.com/max/900/1*s7_EO0rjXAw99RnH1x4s_g.png)\n",
    "- lstm cell takes 3 input\n",
    "    - cell state from $t-1$\n",
    "    - hidden state from $t-1$\n",
    "    - current input $x_t$\n",
    "\n",
    "- lstm cell output \n",
    "    - cell state from $t$\n",
    "    - hidden state from $t$\n",
    "    - output from $t$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use sample data\n",
    "\n",
    "input : length 1 with 10 dimension\\\n",
    "output : length 1 20 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(10, 20, 1) # (input_size, hidden_size, num_layers)\n",
    "input = torch.randn(1, 1, 10) # (Series Length, Batch size, input_dim)\n",
    "h0 = torch.randn(1, 1, 20) # (Series Length, Batch size, input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 20, 1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.input_size, rnn.hidden_size, rnn.num_layers\n",
    "# input size , hidden size,  number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = rnn(input)\n",
    "\n",
    "len(output) # length of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0511,  0.0860, -0.1217,  0.0877,  0.0426,  0.0022,  0.0229,\n",
       "           -0.0829, -0.0583, -0.0324, -0.1867,  0.1178,  0.0094,  0.0187,\n",
       "            0.0352,  0.0582, -0.0778,  0.0369,  0.0825, -0.0036]]],\n",
       "        grad_fn=<StackBackward0>),\n",
       " (tensor([[[-0.0511,  0.0860, -0.1217,  0.0877,  0.0426,  0.0022,  0.0229,\n",
       "            -0.0829, -0.0583, -0.0324, -0.1867,  0.1178,  0.0094,  0.0187,\n",
       "             0.0352,  0.0582, -0.0778,  0.0369,  0.0825, -0.0036]]],\n",
       "         grad_fn=<StackBackward0>),\n",
       "  tensor([[[-0.1416,  0.1849, -0.2309,  0.1433,  0.0767,  0.0040,  0.0547,\n",
       "            -0.1416, -0.1010, -0.0884, -0.4111,  0.2050,  0.0194,  0.0476,\n",
       "             0.0682,  0.0931, -0.1866,  0.0725,  0.1666, -0.0062]]],\n",
       "         grad_fn=<StackBackward0>)))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0], output[1]\n",
    "\n",
    "# output 0 : 1,1,20 vector. output of layer\n",
    "# output 1 : (output and the hidden output & current state output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we changed the sequence of the vector to 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.rand(2, 1, 10) # sequence length 2, batch_size, 1, embedding size 10\n",
    "rnn = nn.LSTM(10, 20, 1) # same model as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0569,  0.1192, -0.0259,  0.0212, -0.0842, -0.0415, -0.1121,\n",
       "            0.0661, -0.0783,  0.0848, -0.0500, -0.0435,  0.0087,  0.0822,\n",
       "           -0.0447,  0.1175, -0.0532, -0.1104,  0.0928, -0.0492]],\n",
       " \n",
       "         [[-0.0831,  0.1595, -0.0117,  0.0178, -0.1352, -0.0932, -0.1217,\n",
       "            0.1179, -0.1499,  0.1582, -0.0862, -0.0483, -0.0161,  0.1349,\n",
       "            0.0220,  0.1528, -0.0120, -0.1601,  0.1565, -0.0897]]],\n",
       "        grad_fn=<StackBackward0>),\n",
       " (tensor([[[-0.0831,  0.1595, -0.0117,  0.0178, -0.1352, -0.0932, -0.1217,\n",
       "             0.1179, -0.1499,  0.1582, -0.0862, -0.0483, -0.0161,  0.1349,\n",
       "             0.0220,  0.1528, -0.0120, -0.1601,  0.1565, -0.0897]]],\n",
       "         grad_fn=<StackBackward0>),\n",
       "  tensor([[[-0.1749,  0.3374, -0.0240,  0.0464, -0.3265, -0.1827, -0.2405,\n",
       "             0.2857, -0.3497,  0.3893, -0.1783, -0.0808, -0.0323,  0.2939,\n",
       "             0.0380,  0.2307, -0.0278, -0.4370,  0.2883, -0.2168]]],\n",
       "         grad_fn=<StackBackward0>)))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = rnn(input) \n",
    "\n",
    "output[0], output[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 20])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].shape \n",
    "# The hidden state output. \n",
    "\n",
    "# (Length 2, batch, embed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0831,  0.1595, -0.0117,  0.0178, -0.1352, -0.0932, -0.1217,\n",
       "            0.1179, -0.1499,  0.1582, -0.0862, -0.0483, -0.0161,  0.1349,\n",
       "            0.0220,  0.1528, -0.0120, -0.1601,  0.1565, -0.0897]]],\n",
       "        grad_fn=<StackBackward0>),\n",
       " tensor([[[-0.1749,  0.3374, -0.0240,  0.0464, -0.3265, -0.1827, -0.2405,\n",
       "            0.2857, -0.3497,  0.3893, -0.1783, -0.0808, -0.0323,  0.2939,\n",
       "            0.0380,  0.2307, -0.0278, -0.4370,  0.2883, -0.2168]]],\n",
       "        grad_fn=<StackBackward0>))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[1]\n",
    "\n",
    "# (hidden state : (sequence_size, batch_size, embedding), current_state : (sequence_size, batch_size, embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out bi-lstm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_lstm = nn.LSTM(10, 20, 1, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = bi_lstm(input) # input : length 2, 1 batch, size 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 40])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].shape \n",
    "\n",
    "# length 2, batch 1, 2 of 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only difference is that the embedding becomes twice the size of the hidden output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = nn.LSTM(10,20,2,bidirectional=True)\n",
    "layer2 = nn.LSTM(40,5,2,bidirectional=True)\n",
    "\n",
    "class extract_tensor(nn.Module):\n",
    "    def forward(self, x):\n",
    "        tensor, _ = x\n",
    "        return tensor\n",
    "\n",
    "model1 = nn.Sequential(\n",
    "    layer1,\n",
    "    extract_tensor(),\n",
    "    layer2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0613, -0.1756, -0.0847, -0.0718, -0.1153]],\n",
       "\n",
       "        [[ 0.1223, -0.0876,  0.0668, -0.0772,  0.0308]],\n",
       "\n",
       "        [[-0.1749, -0.0881, -0.2084, -0.1275, -0.1554]],\n",
       "\n",
       "        [[ 0.0212, -0.0551, -0.0744,  0.0346, -0.0522]]],\n",
       "       grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1(input)[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-LSTM models with some dataset\n",
    "- dataset : Tabular data - titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "project_dir = Path.cwd().parent\n",
    "data_dir = project_dir.joinpath('data')\n",
    "\n",
    "data = data_dir.joinpath('train.csv')\n",
    "data = pd.read_csv(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first tokenize all the values in the dataset\n",
    "data.values\n",
    "\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "row_wise_data = data.values.astype('str').tolist()\n",
    "vocab = build_vocab_from_iterator(row_wise_data, specials = [\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.transforms import VocabTransform, ToTensor, Sequential\n",
    "import torch.nn as nn\n",
    "\n",
    "# make vocab transform layer\n",
    "vocab_transform = VocabTransform(vocab)\n",
    "\n",
    "# get the length of the vocab and do word embedding\n",
    "word_embedding = nn.Embedding(vocab.__len__(), 128)\n",
    "\n",
    "# To tensor\n",
    "transform2tensor = ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_embedding_layer = Sequential(\n",
    "    vocab_transform,\n",
    "    transform2tensor,\n",
    "    word_embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "class TableModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 input_size,\n",
    "                 hidden_size, \n",
    "                 n_layer,\n",
    "                 vocab):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab = vocab\n",
    "        self.vocab_size = self.vocab.__len__()\n",
    "        \n",
    "        # embed vocab\n",
    "        self.vocab_transform = VocabTransform(vocab)\n",
    "        self.totensor = ToTensor()\n",
    "        self.word_embedding = nn.Embedding(self.vocab_size, input_size)\n",
    "        \n",
    "        self.embedding_layer = Sequential(\n",
    "            self.vocab_transform,\n",
    "            self.totensor,\n",
    "            self.word_embedding\n",
    "        )\n",
    "        \n",
    "        # bilstm layers\n",
    "        self.bilstm_layer1 = nn.LSTM(input_size=input_size,\n",
    "                                     hidden_size= hidden_size, \n",
    "                                     num_layers=n_layer,\n",
    "                                     bidirectional =True) \n",
    "        \n",
    "        self.bilstm_layer2 = nn.LSTM(input_size= hidden_size*2,\n",
    "                                     hidden_size= input_size//2,\n",
    "                                     num_layers = n_layer,\n",
    "                                     bidirectional=True)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            self.embedding_layer,\n",
    "            self.bilstm_layer1,\n",
    "            extract_tensor(),\n",
    "            self.bilstm_layer2\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = TableModel(128, 256, 2, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 128])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = my_model(row_wise_data[0])\n",
    "\n",
    "output[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to Sequence\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2a8cca9f7ae2054f045beba9ed73ad6f832c9901de5708c28ae510697f529c7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('2022_transformer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
